{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"53oVyZpv38kr"},"outputs":[],"source":["# ! pip install sqlalchemy==2.0.8 pybigquery==0.5"]},{"cell_type":"markdown","metadata":{"id":"xXxT1Iu7SGn7"},"source":["# 載入參數"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":319,"status":"ok","timestamp":1723602338913,"user":{"displayName":"Tania Huang","userId":"02791943353091573412"},"user_tz":-480},"id":"dhHPlMdFSMGS"},"outputs":[],"source":["# input:uid,start_lat,start_lng,created_at\n","#output: uid,start_lat,start_lng,hour_type,is_holiday,weekday\n","# start_lat,start_lng: round to 2 decimal points\n","# hour_type:convert created_at to taiwan time zone, convert to hour, rules to convert hour to hour type\n","# weekday: convert created_at to taiwan time zone,convert to weekday\n","\n","import pandas as pd\n","from datetime import datetime\n","import pytz\n","\n","def input_data(uid:int,start_lat: float,start_lng: float,created_at: datetime):\n","  uid=uid\n","  # # Convert to datetime\n","  # created_at_dt = datetime.strptime(created_at, '%Y-%m-%d %H:%M:%S')\n","\n","# Define Taiwan timezone\n","  taiwan_tz = pytz.timezone('Asia/Taipei')\n","\n","# Convert to Taiwan timezone\n","  created_at_taiwan = created_at.astimezone(taiwan_tz)\n","\n","# Extract hour\n","  hour = created_at_taiwan.hour\n","\n","# Hour to hour_type\n","  if 7 <= hour <= 9:\n","    category = '早尖峰'\n","  elif 10 <= hour < 12:\n","    category = '早離峰'\n","  elif 13 <= hour <= 16:\n","    category = '午離峰'\n","  elif 17 <= hour <= 19:\n","    category = '晚尖峰'\n","  elif 20 <= hour <= 22:\n","    category = '小晚尖'\n","  elif 2 <= hour <= 6:\n","    category = '凌晨'\n","  else: category='午夜'\n","\n","  hour_type=category\n","\n","# Extract weekday (0=Monday, 6=Sunday) and adjust to 1=Monday, 7=Sunday\n","  weekday = created_at_taiwan.weekday() + 1\n","\n","# is hoilday\n","  if 1<=weekday<=5 :\n","    tag='0'\n","  else:\n","    tag='1'\n","\n","  is_holiday=tag\n","\n","# Round to 2 decimal places\n","  start_lat_rounded = round(start_lat, 2)\n","  start_lng_rounded = round(start_lng, 2)\n","\n","# created_at\n","\n","  created_at=created_at\n","\n","  return uid,start_lat_rounded,start_lng_rounded,hour_type,is_holiday,weekday,created_at\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1723613957008,"user":{"displayName":"Tania Huang","userId":"02791943353091573412"},"user_tz":-480},"id":"Ynv3FofpZK93","outputId":"011792f3-128a-48a4-faca-c1bcea72cea6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution time: 0.00069427490234375 seconds\n"]}],"source":["# Create datetime objects in UTC\n","utc_dt1 = datetime(2024, 8, 13, 7, 0, tzinfo=pytz.utc)\n","\n","start_time = time.time()\n","input_data(2184214,25.09202,121.46401,utc_dt1)\n","end_time = time.time()\n","execution_time = end_time - start_time\n","print(f\"Execution time: {execution_time} seconds\")"]},{"cell_type":"markdown","metadata":{"id":"dHXdvFPh2Jqp"},"source":["# Direct BigQuery Client (Native API)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":529,"status":"ok","timestamp":1723535965989,"user":{"displayName":"Tania Huang","userId":"02791943353091573412"},"user_tz":-480},"id":"wkGQqdk-t5Cx"},"outputs":[],"source":["# from google.cloud import bigquery as bq\n","# from google.oauth2 import service_account\n","# from datetime import datetime\n","# import pandas as pd\n","# import numpy as np\n","# import pytz\n","\n","# def raw_data_producer(uid):\n","#   #讀取權限金鑰\n","#   credentials= service_account.Credentials.from_service_account_file(\"/content/sample_data/bq-key.json\" )\n","#     #設定BigQuery權限\n","#   client = bq.Client(credentials=credentials)\n","\n","#   query = \"\"\"\n","#       select *\n","#       from `william.address_uid_all`\n","#       where uid=\n","#     \"\"\"\n","#   query=query+str(uid)\n","#   result = client.query(query).to_dataframe()\n","#   return result"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4902,"status":"ok","timestamp":1723613991402,"user":{"displayName":"Tania Huang","userId":"02791943353091573412"},"user_tz":-480},"id":"pSNN7Bb4_Cqq","outputId":"e40d7ce4-d735-448e-f5d2-e72e805d527b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution time: 2.0330827236175537 seconds\n"]}],"source":["import time\n","from google.cloud import bigquery\n","from google.oauth2 import service_account\n","\n","def fetch_data_with_uid(uid: int):\n","    # Load credentials and create a BigQuery client\n","    key_path = \"/content/sample_data/bq-key.json\"\n","    project_id = 'taxigo-production'\n","    dataset_id = 'recommend_address'\n","\n","    credentials = service_account.Credentials.from_service_account_file(key_path)\n","    client = bigquery.Client(credentials=credentials, project=project_id)\n","\n","\n","    # Write the SQL query to filter by uid\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{project_id}.{dataset_id}.address_v2_training_data`\n","    WHERE uid = @uid\n","    \"\"\"\n","\n","    # # Create a query job with parameter binding to avoid SQL injection\n","    # query_job = client.query(query, job_config=bigquery.QueryJobConfig(\n","    #     query_parameters=[bigquery.ScalarQueryParameter(\"uid\", \"INT64\", uid)]\n","    # ))\n","\n","   # Set up job configuration\n","    job_config = bigquery.QueryJobConfig(\n","        query_parameters=[bigquery.ScalarQueryParameter(\"uid\", \"INT64\", uid)]\n","    )\n","\n","    # Run the query\n","    query_job = client.query(query, job_config=job_config)\n","\n","    # Fetch and return the results\n","    df = query_job.to_dataframe()\n","    return df\n","\n","# Example usage\n","\n","\n","start_time = time.time()\n","df = fetch_data_with_uid(1274208)\n","end_time = time.time()\n","execution_time = end_time - start_time\n","print(f\"Execution time: {execution_time} seconds\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2754,"status":"ok","timestamp":1723614005563,"user":{"displayName":"Tania Huang","userId":"02791943353091573412"},"user_tz":-480},"id":"wB5EVG1FYLLV","outputId":"3ee4b158-b141-45dd-f6bd-1002440e6345"},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution time: 1.6812825202941895 seconds\n"]}],"source":["import time\n","from google.cloud import bigquery\n","from google.oauth2 import service_account\n","\n","def end_matching_data(uid: int):\n","    # Load credentials and create a BigQuery client\n","    key_path = \"/content/sample_data/bq-key.json\"\n","    project_id = 'taxigo-production'\n","    dataset_id = 'recommend_address'\n","\n","    credentials = service_account.Credentials.from_service_account_file(key_path)\n","    client = bigquery.Client(credentials=credentials, project=project_id)\n","\n","\n","    # Write the SQL query to filter by uid\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{project_id}.{dataset_id}.address_v2_suggestion`\n","    WHERE uid = @uid\n","    \"\"\"\n","\n","   # Set up job configuration\n","    job_config = bigquery.QueryJobConfig(\n","        query_parameters=[bigquery.ScalarQueryParameter(\"uid\", \"INT64\", uid)]\n","    )\n","    # Run the query\n","    query_job = client.query(query, job_config=job_config)\n","\n","    # Fetch and return the results\n","    df = query_job.to_dataframe()\n","    return df\n","\n","# Example usage\n","\n","uid = 1274208\n","start_time = time.time()\n","df = fetch_data_with_uid(uid)\n","end_time = time.time()\n","execution_time = end_time - start_time\n","print(f\"Execution time: {execution_time} seconds\")"]},{"cell_type":"markdown","metadata":{"id":"mWhaoESc2PTz"},"source":["#SQLAlchemy ORM"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1723542428029,"user":{"displayName":"Tania Huang","userId":"02791943353091573412"},"user_tz":-480},"id":"c9mLizZpmq5f","outputId":"53a2daa7-4aea-49f7-e30b-19205121224a"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-24-7147c940c57e>:26: SADeprecationWarning: The dbapi() classmethod on dialect classes has been renamed to import_dbapi().  Implement an import_dbapi() classmethod directly on class <class 'pybigquery.sqlalchemy_bigquery.BigQueryDialect'> to remove this warning; the old .dbapi() classmethod may be maintained for backwards compatibility.\n","  engine = create_engine(connection_string)\n","INFO:sqlalchemy.engine.Engine:BEGIN (implicit)\n"]},{"name":"stdout","output_type":"stream","text":["An error occurred: SQLCompiler.__init__() got multiple values for argument 'cache_key'\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-24-7147c940c57e>:43: SAWarning: Dialect bigquery:bigquery will not make use of SQL compilation caching as it does not set the 'supports_statement_cache' attribute to ``True``.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Dialect maintainers should seek to set this attribute to True after appropriate development and testing for SQLAlchemy 1.4 caching support.   Alternatively, this attribute may be set to False which will disable this warning. (Background on this error at: https://sqlalche.me/e/20/cprf)\n","  result = session.execute(text(\"SELECT * FROM `taxigo-production.william.address_uid_all` LIMIT 10\"))\n"]}],"source":["from google.oauth2 import service_account\n","from sqlalchemy import create_engine, Column, Integer, String, DateTime,text\n","from sqlalchemy.ext.declarative import declarative_base\n","from sqlalchemy.orm import sessionmaker\n","import os\n","\n","def create_bq_engine(key_path: str, project_id: str, dataset_id: str):\n","    \"\"\"\n","    Creates and returns a SQLAlchemy engine connected to BigQuery using a service account key.\n","\n","    Parameters:\n","    - key_path (str): The file path to the service account key JSON file.\n","    - project_id (str): The Google Cloud project ID.\n","    - dataset_id (str): The BigQuery dataset ID.\n","\n","    Returns:\n","    - SQLAlchemy engine connected to BigQuery.\n","    \"\"\"\n","  # Set the environment variable for credentials\n","    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=key_path\n","\n","    # Construct the connection string using the credentials\n","    connection_string = f\"bigquery://{project_id}/{dataset_id}\"\n","\n","    # Create the SQLAlchemy engine with the credentials\n","    engine = create_engine(connection_string)\n","\n","    return engine\n","\n","# Example usage\n","key_path = \"/content/sample_data/bq-key.json\"   # Replace with your actual key file path\n","project_id = 'taxigo-production'  # Replace with your Google Cloud project ID\n","dataset_id = 'william'  # Replace with your BigQuery dataset ID\n","\n","engine = create_bq_engine(key_path, project_id, dataset_id)\n","\n","Session = sessionmaker(bind=engine)\n","session = Session()\n","\n","# Use raw SQL to query the table\n","query = text(\"SELECT * FROM `taxigo-production.william.address_uid_all`\")\n","try:\n","        result = session.execute(text(\"SELECT * FROM `taxigo-production.william.address_uid_all` LIMIT 10\"))\n","        for row in result:\n","            print(row)\n","except Exception as e:\n","        print(f\"An error occurred: {e}\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPOapgkKCGsoWeift4gtaFe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
